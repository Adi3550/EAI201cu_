import pandas as pd
import json

# Load datasets
zoo = pd.read_csv("/content/lab exam/zoo.csv", encoding="utf-8")
classes = pd.read_csv("/content/lab exam/class.csv")

# Standardize the animal name column
for col in zoo.columns:
    if col.lower() in ["animal", "animal_name", "name"]:
        zoo.rename(columns={col: "animal_name"}, inplace=True)

zoo["animal_name"] = zoo["animal_name"].astype(str).str.title()

# Expand comma-separated animal names in class.csv
expanded_rows = []

for i, row in classes.iterrows():
    class_type = row["Class_Type"]
    animal_list = row["Animal_Names"].split(",")
    
    for animal in animal_list:
        expanded_rows.append({
            "animal_name": animal.strip().title(),
            "Class_Type": class_type
        })

class_expanded = pd.DataFrame(expanded_rows)

# Load and normalize JSON metadata
with open("/content/lab exam/auxiliary_metadata.json", "r") as f:
    raw_json = json.load(f)

aux_list = []
for entry in raw_json:
    fixed = {
        "animal_name": entry.get("animal_name", "").title(),
        "conservation_status": entry.get("conservation_status") 
                                or entry.get("conservation") 
                                or entry.get("status"),
        "habitat_type": entry.get("habitat") or entry.get("habitats"),
        "diet": entry.get("diet") or entry.get("diet-type") or entry.get("diet_type")
    }
    aux_list.append(fixed)

aux = pd.DataFrame(aux_list)

# Fix inconsistencies
aux["diet"] = aux["diet"].astype(str).str.lower().replace({"omnivor": "omnivore"})
aux["habitat_type"] = aux["habitat_type"].astype(str).str.lower()
aux["habitat_type"] = (
    aux["habitat_type"]
    .str.replace("fresh water", "freshwater")
    .str.replace("freshwater".lower(), "freshwater")
)
aux["habitat_type"] = aux["habitat_type"].str.replace(" ", "")

# Merge all data
merged = zoo.merge(class_expanded, on="animal_name", how="left")
merged = merged.merge(aux, on="animal_name", how="left")

# Drop rows lacking auxiliary metadata
aux_cols = ["habitat_type", "diet", "conservation_status"]
cleaned = merged.dropna(subset=aux_cols)

cleaned

import pandas as pd
import json

# Load datasets
zoo = pd.read_csv("/content/lab exam/zoo.csv", encoding="utf-8")
classes = pd.read_csv("/content/lab exam/class.csv")

# Standardize the animal name column
for col in zoo.columns:
    if col.lower() in ["animal", "animal_name", "name"]:
        zoo.rename(columns={col: "animal_name"}, inplace=True)

zoo["animal_name"] = zoo["animal_name"].astype(str).str.title()

# Expand comma-separated animal names in class.csv
expanded_rows = []

for i, row in classes.iterrows():
    class_type = row["Class_Type"]
    animal_list = row["Animal_Names"].split(",")
    
    for animal in animal_list:
        expanded_rows.append({
            "animal_name": animal.strip().title(),
            "Class_Type": class_type
        })

class_expanded = pd.DataFrame(expanded_rows)

# Load and normalize JSON metadata
with open("/content/lab exam/auxiliary_metadata.json", "r") as f:
    raw_json = json.load(f)

aux_list = []
for entry in raw_json:
    fixed = {
        "animal_name": entry.get("animal_name", "").title(),
        "conservation_status": entry.get("conservation_status") 
                                or entry.get("conservation") 
                                or entry.get("status"),
        "habitat_type": entry.get("habitat") or entry.get("habitats"),
        "diet": entry.get("diet") or entry.get("diet-type") or entry.get("diet_type")
    }
    aux_list.append(fixed)

aux = pd.DataFrame(aux_list)

# Fix inconsistencies
aux["diet"] = aux["diet"].astype(str).str.lower().replace({"omnivor": "omnivore"})
aux["habitat_type"] = aux["habitat_type"].astype(str).str.lower()
aux["habitat_type"] = (
    aux["habitat_type"]
    .str.replace("fresh water", "freshwater")
    .str.replace("freshwater".lower(), "freshwater")
)
aux["habitat_type"] = aux["habitat_type"].str.replace(" ", "")

# Merge all data
merged = zoo.merge(class_expanded, on="animal_name", how="left")
merged = merged.merge(aux, on="animal_name", how="left")

# Drop rows lacking auxiliary metadata
aux_cols = ["habitat_type", "diet", "conservation_status"]
cleaned = merged.dropna(subset=aux_cols)

cleaned

# TASK 1(f) — Feature Engineering

df = cleaned.copy()

# Normalize habitat values
df["habitat_type"] = df["habitat_type"].str.lower()

# Habitat risk scoring
def habitat_risk(habitat):
    if "marine" in habitat:
        return 3
    elif "freshwater" in habitat:
        return 2
    else:
        return 1

df["habitat_risk_score"] = df["habitat_type"].apply(habitat_risk)

# Diet → trophic level scoring
def trophic_level(diet):
    diet = str(diet).lower()
    if "carnivore" in diet:
        return 3
    elif "omnivore" in diet:
        return 2
    else:
        return 1

df["trophic_level"] = df["diet"].apply(trophic_level)

engineered_feature_names = ["habitat_risk_score", "trophic_level"]

# TASK 1(g) — Summary Output
print("Dataset shape:", df.shape)
print("Missing values:", df.isnull().sum().sum())
print("Duplicate rows:", df.duplicated().sum())

print("\nFirst 3 rows:")
display(df.head(3))

print("\nEngineered features:", engineered_feature_names)


